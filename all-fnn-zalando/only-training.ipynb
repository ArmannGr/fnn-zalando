{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T11:52:44.038325Z",
     "start_time": "2025-01-20T11:50:42.887816Z"
    }
   },
   "source": [
    "import numpy\n",
    "# scipy.special für die Sigmoid-Funktion expit()\n",
    "import scipy.special\n",
    "# Bibliothek zum Plotten von Arrays\n",
    "import matplotlib.pyplot as plt\n",
    "# sicherstellen, dass die Plots in diesem Notebook und nicht in einem externen Fenster angezeigt werden\n",
    "%matplotlib inline\n",
    "\n",
    "# Definition der neuronalen Netzwerkklasse\n",
    "class neuralNetwork:\n",
    "\n",
    "    # Initialisierung des neuronalen Netzwerks\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # Anzahl der Nodes in jeder Input-, hidden und output layer festlegen\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # Gewichtsmatrizen, wih und who\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # Lernrate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # Aktivierungsfunktion ist die Sigmoid-Funktion\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # Trainieren des neuronalen Netzwerks\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # Inputs in ein 2D-Array umwandeln\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "\n",
    "        # Signale in dem Hidden Layer berechnen\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # Signale berechnen, die aus dem Hidden Layer hervorgehen\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # Signale in dem endgültigen Output Layer berechnen\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # Signale berechnen, die aus dem endgültigen Output Layer  hervorgehen\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # Fehler in dem Output Layer ist (Ziel - Ist)\n",
    "        output_errors = targets - final_outputs\n",
    "        # Fehler in dem Hidden Layer ist der output_errors, aufgeteilt nach Gewichten, neu kombiniert an den Hidden Nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "        # Gewichte für die Verbindungen zwischen den hidden und den Output Layers aktualisieren\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)),\n",
    "                                        numpy.transpose(hidden_outputs))\n",
    "\n",
    "        # Gewichte für die Verbindungen zwischen den Input- und den Hidden Layern aktualisieren\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)),\n",
    "                                        numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # Abfragen des neuronalen Netzwerks\n",
    "    def query(self, inputs_list):\n",
    "        # Input List in ein 2D-Array umwandeln\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # Signale in die Hidden Layern berechnen\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # Signale berechnen, die aus dem Hidden Layer hervorgehen\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # Signale in den endgültigen Output Layer berechnen\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # Signale berechnen, die aus dem endgültigen Output Layer hervorgehen\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "\n",
    "\n",
    "# Anzahl an input, hidden und output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 1\n",
    "\n",
    "# Lernrate\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Erstelle Instanz des neuronalen Netzwerks\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "with open(\"../data/fashion-mnist_train.csv\", 'r') as training_data_file:\n",
    "    training_data_list = training_data_file.readlines()[1:]\n",
    "\n",
    "with open(\"../data/fashion-mnist_test.csv\", 'r') as test_data_file:\n",
    "    test_data_list = test_data_file.readlines()[1:]\n",
    "# Erstellen Sie eine Liste von 10 Modellen\n",
    "models = []\n",
    "for i in range(10):\n",
    "    models.append(neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate))\n",
    "# Epochen ist die Anzahl der Male, die der Trainingsdatensatz zum Training verwendet wird\n",
    "epochs = 1\n",
    "\n",
    "# Erstellen Sie eine Liste von 10 Ensembles, die jeweils 10 Modelle enthalten\n",
    "ensembles = []\n",
    "for _ in range(10):\n",
    "    ensemble = []\n",
    "    for i in range(10):\n",
    "        ensemble.append(neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate))\n",
    "    ensembles.append(ensemble)\n",
    "\n",
    "\n",
    "# Zusätzliche Vorbereitungen für Auswertung\n",
    "training_details = {\n",
    "    'class_samples': {},\n",
    "    'ensemble_predictions': []\n",
    "}\n",
    "\n",
    "# Trainiere jedes Modell in jedem Ensemble auf die jeweilige Klasse gegen den Rest\n",
    "for ensemble_index, ensemble in enumerate(ensembles):\n",
    "    ensemble_predictions = []\n",
    "    for class_index in range(10):\n",
    "        # Zähle Samples pro Klasse\n",
    "        class_samples = [record for record in training_data_list\n",
    "                         if int(record.split(',')[0]) == class_index]\n",
    "        training_details['class_samples'][class_index] = len(class_samples)\n",
    "\n",
    "        for model in ensemble:\n",
    "            class_specific_predictions = []\n",
    "            for record in class_samples:\n",
    "                all_values = record.split(',')\n",
    "                inputs = (numpy.asarray(all_values[1:], dtype=float) / 255.0 * 0.99) + 0.01\n",
    "                target = numpy.array([0.99 if int(all_values[0]) == class_index else 0.01])\n",
    "\n",
    "                # Trainiere Modell\n",
    "                model.train(inputs, target)\n",
    "\n",
    "                # Speichere Vorhersagen für spätere Analyse\n",
    "                prediction = model.query(inputs)[0]\n",
    "                class_specific_predictions.append({\n",
    "                    'true_class': int(all_values[0]),\n",
    "                    'prediction': prediction\n",
    "                })\n",
    "\n",
    "            ensemble_predictions.extend(class_specific_predictions)\n",
    "\n",
    "    training_details['ensemble_predictions'].append(ensemble_predictions)\n",
    "\n",
    "# Zusätzliche Analysemöglichkeiten vorbereiten\n",
    "training_details['total_ensembles'] = len(ensembles)\n",
    "training_details['total_models_per_ensemble'] = len(ensembles[0])"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 130\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m class_samples:\n\u001B[1;32m    129\u001B[0m     all_values \u001B[38;5;241m=\u001B[39m record\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 130\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m (\u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_values\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.99\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m    131\u001B[0m     target \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0.99\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mint\u001B[39m(all_values[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m class_index \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0.01\u001B[39m])\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;66;03m# Trainiere Modell\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T11:52:44.097935Z",
     "start_time": "2025-01-20T11:49:16.166899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testen Sie jedes Bild mit allen Modellen in allen Ensembles\n",
    "scorecard = []\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    inputs = (numpy.asarray(all_values[1:], dtype=float) / 255.0 * 0.99) + 0.01\n",
    "    ensemble_outputs = []\n",
    "    for ensemble in ensembles:\n",
    "        outputs = [model.query(inputs) for model in ensemble]\n",
    "        predicted_labels = [i for i, output in enumerate(outputs) if output[0] > 0.5]\n",
    "        ensemble_outputs.append(predicted_labels)\n",
    "    # Aggregieren Sie die Vorhersagen aller Ensembles\n",
    "    all_predictions = sum(ensemble_outputs, [])\n",
    "    if all_predictions:\n",
    "        final_prediction = max(set(all_predictions), key=all_predictions.count)\n",
    "        if correct_label == final_prediction:\n",
    "            scorecard.append(1)\n",
    "        else:\n",
    "            scorecard.append(0)\n",
    "    else:\n",
    "        # Behandeln Sie den Fall, in dem kein Modell ein Label mit einer Konfidenz > 0.5 vorhersagt\n",
    "        scorecard.append(0)"
   ],
   "id": "1669d7fe3602304c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T11:52:44.098088Z",
     "start_time": "2025-01-20T11:49:22.170402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Berechne die Leistung\n",
    "performance = sum(scorecard) / len(scorecard)\n",
    "print(f'Performance: {performance}')\n",
    "\n"
   ],
   "id": "a03f0ff84c791a7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: 0.1\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
